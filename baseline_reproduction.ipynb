{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "baseline_reproduction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ond7-1SjwG2I"
      },
      "source": [
        "## 1.1 Setup environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olLjglUg34RS",
        "outputId": "0a695cd1-4062-4edf-91a3-c44443cdb346"
      },
      "source": [
        "%%shell\n",
        "# Get data\n",
        "git clone https://github.com/CS115-fake-news-detection/fake-news-reasoning.git\n",
        "echo \"Downloading data...\"\n",
        "wget -q https://www.dropbox.com/s/3v5oy3eddg3506j/multi_fc_publicdata.zip\n",
        "echo \"Data downloaded\"\n",
        "unzip -q multi_fc_publicdata.zip\n",
        "rm multi_fc_publicdata.zip\n",
        "echo \"Data unzipped\"\n",
        "\n",
        "# So we can later import model_selection.py\n",
        "!cp fake-news-reasoning/code-acl/bias/model_selection.py ."
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'fake-news-reasoning'...\n",
            "remote: Enumerating objects: 51, done.\u001b[K\n",
            "remote: Counting objects: 100% (51/51), done.\u001b[K\n",
            "remote: Compressing objects: 100% (40/40), done.\u001b[K\n",
            "remote: Total 51 (delta 12), reused 7 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (51/51), done.\n",
            "Downloading data...\n",
            "Data downloaded\n",
            "Data unzipped\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JI_693EHyKlV",
        "outputId": "ec8ad61c-24a7-4941-c79b-e74d6a34a310"
      },
      "source": [
        "!pip install -r colab_requirements.txt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining hpsklearn from git+https://github.com/hyperopt/hyperopt-sklearn.git@fd718c44fc440bd6e2718ec1442b1af58cafcb18#egg=hpsklearn (from -r colab_requirements.txt (line 22))\n",
            "  Cloning https://github.com/hyperopt/hyperopt-sklearn.git (to revision fd718c44fc440bd6e2718ec1442b1af58cafcb18) to ./src/hpsklearn\n",
            "  Running command git clone -q https://github.com/hyperopt/hyperopt-sklearn.git /content/src/hpsklearn\n",
            "  Running command git rev-parse -q --verify 'sha^fd718c44fc440bd6e2718ec1442b1af58cafcb18'\n",
            "  Running command git fetch -q https://github.com/hyperopt/hyperopt-sklearn.git fd718c44fc440bd6e2718ec1442b1af58cafcb18\n",
            "  Running command git checkout -q fd718c44fc440bd6e2718ec1442b1af58cafcb18\n",
            "Collecting absl-py==0.11.0\n",
            "  Downloading absl_py-0.11.0-py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 5.2 MB/s \n",
            "\u001b[?25hCollecting arrow==0.17.0\n",
            "  Downloading arrow-0.17.0-py2.py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 7.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.7/dist-packages (from -r colab_requirements.txt (line 3)) (1.6.3)\n",
            "Collecting binaryornot==0.4.4\n",
            "  Downloading binaryornot-0.4.4-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting cachetools==4.1.1\n",
            "  Downloading cachetools-4.1.1-py3-none-any.whl (10 kB)\n",
            "Collecting certifi==2020.11.8\n",
            "  Downloading certifi-2020.11.8-py2.py3-none-any.whl (155 kB)\n",
            "\u001b[K     |████████████████████████████████| 155 kB 55.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet==3.0.4 in /usr/local/lib/python3.7/dist-packages (from -r colab_requirements.txt (line 7)) (3.0.4)\n",
            "Requirement already satisfied: click==7.1.2 in /usr/local/lib/python3.7/dist-packages (from -r colab_requirements.txt (line 8)) (7.1.2)\n",
            "Collecting cloudpickle==1.6.0\n",
            "  Downloading cloudpickle-1.6.0-py3-none-any.whl (23 kB)\n",
            "Collecting cookiecutter==1.7.2\n",
            "  Downloading cookiecutter-1.7.2-py2.py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: cycler==0.10.0 in /usr/local/lib/python3.7/dist-packages (from -r colab_requirements.txt (line 11)) (0.10.0)\n",
            "Requirement already satisfied: decorator==4.4.2 in /usr/local/lib/python3.7/dist-packages (from -r colab_requirements.txt (line 13)) (4.4.2)\n",
            "Collecting filelock==3.0.12\n",
            "  Downloading filelock-3.0.12-py3-none-any.whl (7.6 kB)\n",
            "Collecting future==0.18.2\n",
            "  Downloading future-0.18.2.tar.gz (829 kB)\n",
            "\u001b[K     |████████████████████████████████| 829 kB 68.4 MB/s \n",
            "\u001b[?25hCollecting gast==0.3.3\n",
            "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
            "Collecting google-auth==1.23.0\n",
            "  Downloading google_auth-1.23.0-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[K     |████████████████████████████████| 114 kB 64.7 MB/s \n",
            "\u001b[?25hCollecting google-auth-oauthlib==0.4.2\n",
            "  Downloading google_auth_oauthlib-0.4.2-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: google-pasta==0.2.0 in /usr/local/lib/python3.7/dist-packages (from -r colab_requirements.txt (line 19)) (0.2.0)\n",
            "Collecting grpcio==1.33.2\n",
            "  Downloading grpcio-1.33.2-cp37-cp37m-manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 76.2 MB/s \n",
            "\u001b[?25hCollecting h5py==2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 55.5 MB/s \n",
            "\u001b[?25hCollecting hyperopt==0.2.5\n",
            "  Downloading hyperopt-0.2.5-py2.py3-none-any.whl (965 kB)\n",
            "\u001b[K     |████████████████████████████████| 965 kB 19.2 MB/s \n",
            "\u001b[?25hCollecting hypopt==1.0.9\n",
            "  Downloading hypopt-1.0.9-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: idna==2.10 in /usr/local/lib/python3.7/dist-packages (from -r colab_requirements.txt (line 25)) (2.10)\n",
            "Collecting importlib-metadata==3.1.0\n",
            "  Downloading importlib_metadata-3.1.0-py2.py3-none-any.whl (9.3 kB)\n",
            "Collecting Jinja2==2.11.2\n",
            "  Downloading Jinja2-2.11.2-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 70.3 MB/s \n",
            "\u001b[?25hCollecting jinja2-time==0.2.0\n",
            "  Downloading jinja2_time-0.2.0-py2.py3-none-any.whl (6.4 kB)\n",
            "Collecting joblib==0.17.0\n",
            "  Downloading joblib-0.17.0-py3-none-any.whl (301 kB)\n",
            "\u001b[K     |████████████████████████████████| 301 kB 67.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Keras-Preprocessing==1.1.2 in /usr/local/lib/python3.7/dist-packages (from -r colab_requirements.txt (line 30)) (1.1.2)\n",
            "Collecting kiwisolver==1.3.1\n",
            "  Downloading kiwisolver-1.3.1-cp37-cp37m-manylinux1_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 64.6 MB/s \n",
            "\u001b[?25hCollecting Markdown==3.3.3\n",
            "  Downloading Markdown-3.3.3-py3-none-any.whl (96 kB)\n",
            "\u001b[K     |████████████████████████████████| 96 kB 6.6 MB/s \n",
            "\u001b[?25hCollecting MarkupSafe==1.1.1\n",
            "  Downloading MarkupSafe-1.1.1-cp37-cp37m-manylinux2010_x86_64.whl (33 kB)\n",
            "Collecting matplotlib==3.3.3\n",
            "  Downloading matplotlib-3.3.3-cp37-cp37m-manylinux1_x86_64.whl (11.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.6 MB 33.2 MB/s \n",
            "\u001b[?25hCollecting networkx==2.5\n",
            "  Downloading networkx-2.5-py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 44.4 MB/s \n",
            "\u001b[?25hCollecting nose==1.3.7\n",
            "  Downloading nose-1.3.7-py3-none-any.whl (154 kB)\n",
            "\u001b[K     |████████████████████████████████| 154 kB 84.1 MB/s \n",
            "\u001b[?25hCollecting numpy==1.18.5\n",
            "  Downloading numpy-1.18.5-cp37-cp37m-manylinux1_x86_64.whl (20.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 20.1 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting oauthlib==3.1.0\n",
            "  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
            "\u001b[K     |████████████████████████████████| 147 kB 51.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum==3.3.0 in /usr/local/lib/python3.7/dist-packages (from -r colab_requirements.txt (line 39)) (3.3.0)\n",
            "Collecting packaging==20.7\n",
            "  Downloading packaging-20.7-py2.py3-none-any.whl (35 kB)\n",
            "Collecting pandas==1.1.4\n",
            "  Downloading pandas-1.1.4-cp37-cp37m-manylinux1_x86_64.whl (9.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.5 MB 36.9 MB/s \n",
            "\u001b[?25hCollecting Pillow==8.0.1\n",
            "  Downloading Pillow-8.0.1-cp37-cp37m-manylinux1_x86_64.whl (2.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2 MB 56.0 MB/s \n",
            "\u001b[?25hCollecting poyo==0.5.0\n",
            "  Downloading poyo-0.5.0-py2.py3-none-any.whl (10 kB)\n",
            "Collecting protobuf==3.14.0\n",
            "  Downloading protobuf-3.14.0-cp37-cp37m-manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 54.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyasn1==0.4.8 in /usr/local/lib/python3.7/dist-packages (from -r colab_requirements.txt (line 45)) (0.4.8)\n",
            "Requirement already satisfied: pyasn1-modules==0.2.8 in /usr/local/lib/python3.7/dist-packages (from -r colab_requirements.txt (line 46)) (0.2.8)\n",
            "Requirement already satisfied: pyparsing==2.4.7 in /usr/local/lib/python3.7/dist-packages (from -r colab_requirements.txt (line 47)) (2.4.7)\n",
            "Collecting python-dateutil==2.8.1\n",
            "  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
            "\u001b[K     |████████████████████████████████| 227 kB 51.2 MB/s \n",
            "\u001b[?25hCollecting python-slugify==4.0.1\n",
            "  Downloading python-slugify-4.0.1.tar.gz (11 kB)\n",
            "Collecting pytorch-nlp==0.5.0\n",
            "  Downloading pytorch_nlp-0.5.0-py3-none-any.whl (90 kB)\n",
            "\u001b[K     |████████████████████████████████| 90 kB 10.5 MB/s \n",
            "\u001b[?25hCollecting pytz==2020.4\n",
            "  Downloading pytz-2020.4-py2.py3-none-any.whl (509 kB)\n",
            "\u001b[K     |████████████████████████████████| 509 kB 37.5 MB/s \n",
            "\u001b[?25hCollecting regex==2020.11.13\n",
            "  Downloading regex-2020.11.13-cp37-cp37m-manylinux2014_x86_64.whl (719 kB)\n",
            "\u001b[K     |████████████████████████████████| 719 kB 53.9 MB/s \n",
            "\u001b[?25hCollecting requests==2.25.0\n",
            "  Downloading requests-2.25.0-py2.py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 9.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests-oauthlib==1.3.0 in /usr/local/lib/python3.7/dist-packages (from -r colab_requirements.txt (line 54)) (1.3.0)\n",
            "Collecting rsa==4.6\n",
            "  Downloading rsa-4.6-py3-none-any.whl (47 kB)\n",
            "\u001b[K     |████████████████████████████████| 47 kB 5.2 MB/s \n",
            "\u001b[?25hCollecting sacremoses==0.0.43\n",
            "  Downloading sacremoses-0.0.43.tar.gz (883 kB)\n",
            "\u001b[K     |████████████████████████████████| 883 kB 56.6 MB/s \n",
            "\u001b[?25hCollecting scikit-learn==0.23.2\n",
            "  Downloading scikit_learn-0.23.2-cp37-cp37m-manylinux1_x86_64.whl (6.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8 MB 53.7 MB/s \n",
            "\u001b[?25hCollecting scipy==1.5.4\n",
            "  Downloading scipy-1.5.4-cp37-cp37m-manylinux1_x86_64.whl (25.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.9 MB 1.4 MB/s \n",
            "\u001b[?25hCollecting seaborn==0.11.1\n",
            "  Downloading seaborn-0.11.1-py3-none-any.whl (285 kB)\n",
            "\u001b[K     |████████████████████████████████| 285 kB 59.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six==1.15.0 in /usr/local/lib/python3.7/dist-packages (from -r colab_requirements.txt (line 60)) (1.15.0)\n",
            "Collecting tensorboard==2.4.0\n",
            "  Downloading tensorboard-2.4.0-py3-none-any.whl (10.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.6 MB 9.3 MB/s \n",
            "\u001b[?25hCollecting tensorboard-plugin-wit==1.7.0\n",
            "  Downloading tensorboard_plugin_wit-1.7.0-py3-none-any.whl (779 kB)\n",
            "\u001b[K     |████████████████████████████████| 779 kB 68.9 MB/s \n",
            "\u001b[?25hCollecting tensorflow-gpu==2.3.1\n",
            "  Downloading tensorflow_gpu-2.3.1-cp37-cp37m-manylinux2010_x86_64.whl (320.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 320.4 MB 26 kB/s \n",
            "\u001b[?25hCollecting tensorflow-gpu-estimator==2.3.0\n",
            "  Downloading tensorflow_gpu_estimator-2.3.0-py2.py3-none-any.whl (474 kB)\n",
            "\u001b[K     |████████████████████████████████| 474 kB 60.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor==1.1.0 in /usr/local/lib/python3.7/dist-packages (from -r colab_requirements.txt (line 65)) (1.1.0)\n",
            "Requirement already satisfied: text-unidecode==1.3 in /usr/local/lib/python3.7/dist-packages (from -r colab_requirements.txt (line 66)) (1.3)\n",
            "Collecting threadpoolctl==2.1.0\n",
            "  Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
            "Collecting tokenizers==0.9.4\n",
            "  Downloading tokenizers-0.9.4-cp37-cp37m-manylinux2010_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 46.2 MB/s \n",
            "\u001b[?25hCollecting tqdm==4.54.0\n",
            "  Downloading tqdm-4.54.0-py2.py3-none-any.whl (69 kB)\n",
            "\u001b[K     |████████████████████████████████| 69 kB 7.9 MB/s \n",
            "\u001b[?25hCollecting transformers==4.0.0\n",
            "  Downloading transformers-4.0.0-py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 26.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions==3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from -r colab_requirements.txt (line 72)) (3.7.4.3)\n",
            "Collecting urllib3==1.26.2\n",
            "  Downloading urllib3-1.26.2-py2.py3-none-any.whl (136 kB)\n",
            "\u001b[K     |████████████████████████████████| 136 kB 72.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Werkzeug==1.0.1 in /usr/local/lib/python3.7/dist-packages (from -r colab_requirements.txt (line 74)) (1.0.1)\n",
            "Collecting wincertstore==0.2\n",
            "  Downloading wincertstore-0.2-py2.py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: wrapt==1.12.1 in /usr/local/lib/python3.7/dist-packages (from -r colab_requirements.txt (line 76)) (1.12.1)\n",
            "Collecting zipp==3.4.0\n",
            "  Downloading zipp-3.4.0-py3-none-any.whl (5.2 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse==1.6.3->-r colab_requirements.txt (line 3)) (0.37.0)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-auth==1.23.0->-r colab_requirements.txt (line 17)) (57.4.0)\n",
            "Collecting tensorflow-estimator<2.4.0,>=2.3.0\n",
            "  Downloading tensorflow_estimator-2.3.0-py2.py3-none-any.whl (459 kB)\n",
            "\u001b[K     |████████████████████████████████| 459 kB 28.0 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: future, python-slugify, sacremoses\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=7a6f6b1df371996eb3521f147941ab64af76c7a130829f2e88fe4bcf446ada74\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
            "  Building wheel for python-slugify (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-slugify: filename=python_slugify-4.0.1-py2.py3-none-any.whl size=6781 sha256=363e3eef413f24ad2a974df37d1cc504925fc61f00e871a83e010607fbe0f2a2\n",
            "  Stored in directory: /root/.cache/pip/wheels/48/1b/6f/5c1cfab22eacbe0095fc619786da6571b55253653c71324b5c\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-py3-none-any.whl size=893250 sha256=8dcabf2f50d4270c192f6d948b6200d331a10db617cb27ae92237717d0781a3d\n",
            "  Stored in directory: /root/.cache/pip/wheels/69/09/d1/bf058f7d6fa0ecba2ce7c66be3b8d012beb4bf61a6e0c101c0\n",
            "Successfully built future python-slugify sacremoses\n",
            "Installing collected packages: urllib3, certifi, zipp, rsa, requests, oauthlib, cachetools, python-dateutil, numpy, MarkupSafe, importlib-metadata, google-auth, tqdm, threadpoolctl, tensorboard-plugin-wit, scipy, regex, pytz, protobuf, Pillow, networkx, Markdown, kiwisolver, joblib, Jinja2, grpcio, google-auth-oauthlib, future, cloudpickle, arrow, absl-py, tokenizers, tensorflow-estimator, tensorboard, scikit-learn, sacremoses, python-slugify, poyo, pandas, packaging, nose, matplotlib, jinja2-time, hyperopt, h5py, gast, filelock, binaryornot, wincertstore, transformers, tensorflow-gpu-estimator, tensorflow-gpu, seaborn, pytorch-nlp, hypopt, hpsklearn, cookiecutter\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2021.5.30\n",
            "    Uninstalling certifi-2021.5.30:\n",
            "      Successfully uninstalled certifi-2021.5.30\n",
            "  Attempting uninstall: zipp\n",
            "    Found existing installation: zipp 3.6.0\n",
            "    Uninstalling zipp-3.6.0:\n",
            "      Successfully uninstalled zipp-3.6.0\n",
            "  Attempting uninstall: rsa\n",
            "    Found existing installation: rsa 4.7.2\n",
            "    Uninstalling rsa-4.7.2:\n",
            "      Successfully uninstalled rsa-4.7.2\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: oauthlib\n",
            "    Found existing installation: oauthlib 3.1.1\n",
            "    Uninstalling oauthlib-3.1.1:\n",
            "      Successfully uninstalled oauthlib-3.1.1\n",
            "  Attempting uninstall: cachetools\n",
            "    Found existing installation: cachetools 4.2.4\n",
            "    Uninstalling cachetools-4.2.4:\n",
            "      Successfully uninstalled cachetools-4.2.4\n",
            "  Attempting uninstall: python-dateutil\n",
            "    Found existing installation: python-dateutil 2.8.2\n",
            "    Uninstalling python-dateutil-2.8.2:\n",
            "      Successfully uninstalled python-dateutil-2.8.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 2.0.1\n",
            "    Uninstalling MarkupSafe-2.0.1:\n",
            "      Successfully uninstalled MarkupSafe-2.0.1\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 4.8.1\n",
            "    Uninstalling importlib-metadata-4.8.1:\n",
            "      Successfully uninstalled importlib-metadata-4.8.1\n",
            "  Attempting uninstall: google-auth\n",
            "    Found existing installation: google-auth 1.35.0\n",
            "    Uninstalling google-auth-1.35.0:\n",
            "      Successfully uninstalled google-auth-1.35.0\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.62.3\n",
            "    Uninstalling tqdm-4.62.3:\n",
            "      Successfully uninstalled tqdm-4.62.3\n",
            "  Attempting uninstall: tensorboard-plugin-wit\n",
            "    Found existing installation: tensorboard-plugin-wit 1.8.0\n",
            "    Uninstalling tensorboard-plugin-wit-1.8.0:\n",
            "      Successfully uninstalled tensorboard-plugin-wit-1.8.0\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2019.12.20\n",
            "    Uninstalling regex-2019.12.20:\n",
            "      Successfully uninstalled regex-2019.12.20\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2018.9\n",
            "    Uninstalling pytz-2018.9:\n",
            "      Successfully uninstalled pytz-2018.9\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.17.3\n",
            "    Uninstalling protobuf-3.17.3:\n",
            "      Successfully uninstalled protobuf-3.17.3\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 2.6.3\n",
            "    Uninstalling networkx-2.6.3:\n",
            "      Successfully uninstalled networkx-2.6.3\n",
            "  Attempting uninstall: Markdown\n",
            "    Found existing installation: Markdown 3.3.4\n",
            "    Uninstalling Markdown-3.3.4:\n",
            "      Successfully uninstalled Markdown-3.3.4\n",
            "  Attempting uninstall: kiwisolver\n",
            "    Found existing installation: kiwisolver 1.3.2\n",
            "    Uninstalling kiwisolver-1.3.2:\n",
            "      Successfully uninstalled kiwisolver-1.3.2\n",
            "  Attempting uninstall: joblib\n",
            "    Found existing installation: joblib 1.0.1\n",
            "    Uninstalling joblib-1.0.1:\n",
            "      Successfully uninstalled joblib-1.0.1\n",
            "  Attempting uninstall: Jinja2\n",
            "    Found existing installation: Jinja2 2.11.3\n",
            "    Uninstalling Jinja2-2.11.3:\n",
            "      Successfully uninstalled Jinja2-2.11.3\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.41.0\n",
            "    Uninstalling grpcio-1.41.0:\n",
            "      Successfully uninstalled grpcio-1.41.0\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 0.4.6\n",
            "    Uninstalling google-auth-oauthlib-0.4.6:\n",
            "      Successfully uninstalled google-auth-oauthlib-0.4.6\n",
            "  Attempting uninstall: future\n",
            "    Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 1.3.0\n",
            "    Uninstalling cloudpickle-1.3.0:\n",
            "      Successfully uninstalled cloudpickle-1.3.0\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 0.12.0\n",
            "    Uninstalling absl-py-0.12.0:\n",
            "      Successfully uninstalled absl-py-0.12.0\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.6.0\n",
            "    Uninstalling tensorflow-estimator-2.6.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.6.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.6.0\n",
            "    Uninstalling tensorboard-2.6.0:\n",
            "      Successfully uninstalled tensorboard-2.6.0\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "  Attempting uninstall: python-slugify\n",
            "    Found existing installation: python-slugify 5.0.2\n",
            "    Uninstalling python-slugify-5.0.2:\n",
            "      Successfully uninstalled python-slugify-5.0.2\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.1.5\n",
            "    Uninstalling pandas-1.1.5:\n",
            "      Successfully uninstalled pandas-1.1.5\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 21.0\n",
            "    Uninstalling packaging-21.0:\n",
            "      Successfully uninstalled packaging-21.0\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "  Attempting uninstall: hyperopt\n",
            "    Found existing installation: hyperopt 0.1.2\n",
            "    Uninstalling hyperopt-0.1.2:\n",
            "      Successfully uninstalled hyperopt-0.1.2\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.3.0\n",
            "    Uninstalling filelock-3.3.0:\n",
            "      Successfully uninstalled filelock-3.3.0\n",
            "  Attempting uninstall: seaborn\n",
            "    Found existing installation: seaborn 0.11.2\n",
            "    Uninstalling seaborn-0.11.2:\n",
            "      Successfully uninstalled seaborn-0.11.2\n",
            "  Running setup.py develop for hpsklearn\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.6.0 requires gast==0.4.0, but you have gast 0.3.3 which is incompatible.\n",
            "tensorflow 2.6.0 requires grpcio<2.0,>=1.37.0, but you have grpcio 1.33.2 which is incompatible.\n",
            "tensorflow 2.6.0 requires h5py~=3.1.0, but you have h5py 2.10.0 which is incompatible.\n",
            "tensorflow 2.6.0 requires numpy~=1.19.2, but you have numpy 1.18.5 which is incompatible.\n",
            "tensorflow 2.6.0 requires tensorboard~=2.6, but you have tensorboard 2.4.0 which is incompatible.\n",
            "tensorflow 2.6.0 requires tensorflow-estimator~=2.6, but you have tensorflow-estimator 2.3.0 which is incompatible.\n",
            "pymc3 3.11.4 requires cachetools>=4.2.1, but you have cachetools 4.1.1 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.25.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed Jinja2-2.11.2 Markdown-3.3.3 MarkupSafe-1.1.1 Pillow-8.0.1 absl-py-0.11.0 arrow-0.17.0 binaryornot-0.4.4 cachetools-4.1.1 certifi-2020.11.8 cloudpickle-1.6.0 cookiecutter-1.7.2 filelock-3.0.12 future-0.18.2 gast-0.3.3 google-auth-1.23.0 google-auth-oauthlib-0.4.2 grpcio-1.33.2 h5py-2.10.0 hpsklearn-0.0.3 hyperopt-0.2.5 hypopt-1.0.9 importlib-metadata-3.1.0 jinja2-time-0.2.0 joblib-0.17.0 kiwisolver-1.3.1 matplotlib-3.3.3 networkx-2.5 nose-1.3.7 numpy-1.18.5 oauthlib-3.1.0 packaging-20.7 pandas-1.1.4 poyo-0.5.0 protobuf-3.14.0 python-dateutil-2.8.1 python-slugify-4.0.1 pytorch-nlp-0.5.0 pytz-2020.4 regex-2020.11.13 requests-2.25.0 rsa-4.6 sacremoses-0.0.43 scikit-learn-0.23.2 scipy-1.5.4 seaborn-0.11.1 tensorboard-2.4.0 tensorboard-plugin-wit-1.7.0 tensorflow-estimator-2.3.0 tensorflow-gpu-2.3.1 tensorflow-gpu-estimator-2.3.0 threadpoolctl-2.1.0 tokenizers-0.9.4 tqdm-4.54.0 transformers-4.0.0 urllib3-1.26.2 wincertstore-0.2 zipp-3.4.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "dateutil",
                  "google",
                  "kiwisolver",
                  "matplotlib",
                  "mpl_toolkits",
                  "numpy",
                  "pandas",
                  "pytz"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJrKlKFjTG0R",
        "outputId": "5ab6e02e-4d5a-450d-8076-77aa000b22b8"
      },
      "source": [
        "# Install correct versions of torch\n",
        "!pip install torch==1.7.0+cu101 torchvision==0.8.1+cu101 torchaudio===0.7.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.7.0+cu101\n",
            "  Downloading https://download.pytorch.org/whl/cu101/torch-1.7.0%2Bcu101-cp37-cp37m-linux_x86_64.whl (735.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 735.3 MB 20 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.8.1+cu101\n",
            "  Downloading https://download.pytorch.org/whl/cu101/torchvision-0.8.1%2Bcu101-cp37-cp37m-linux_x86_64.whl (12.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.7 MB 57.2 MB/s \n",
            "\u001b[?25hCollecting torchaudio===0.7.0\n",
            "  Downloading torchaudio-0.7.0-cp37-cp37m-manylinux1_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 4.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0+cu101) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0+cu101) (1.18.5)\n",
            "Collecting dataclasses\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0+cu101) (0.18.2)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.1+cu101) (8.0.1)\n",
            "Installing collected packages: dataclasses, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.9.0+cu111\n",
            "    Uninstalling torch-1.9.0+cu111:\n",
            "      Successfully uninstalled torch-1.9.0+cu111\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.10.0+cu111\n",
            "    Uninstalling torchvision-0.10.0+cu111:\n",
            "      Successfully uninstalled torchvision-0.10.0+cu111\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.10.0 requires torch==1.9.0, but you have torch 1.7.0+cu101 which is incompatible.\u001b[0m\n",
            "Successfully installed dataclasses-0.6 torch-1.7.0+cu101 torchaudio-0.7.0 torchvision-0.8.1+cu101\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JFhQXKAV5bp"
      },
      "source": [
        "import model_selection"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1f6-aTk_0237",
        "outputId": "9ed0afe5-6935-41f2-b9fe-3f28d74420ce"
      },
      "source": [
        "!python fake-news-reasoning/code-acl/bias/main.py --dataset snes --inputtype CLAIM_ONLY --model bow"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-10-23 22:57:14.960040: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "[Oct 23, 22:57:16] Namespace(batchsize=2, dataset='snes', eval_per_epoch=1, filter_websites=0, inputtype='CLAIM_ONLY', lr=0.0001, lstm_dropout=0.1, lstm_hidden_dim=128, lstm_layers=1, model='bow')\n",
            "len 5069 , false (64.3\\%), mostly false (7.5\\%), mixture (12.3\\%), mostly true (2.8\\%), true (13.0\\%)\n",
            "len 13581 , false (29.7\\%), mostly false (17.0\\%), mixture (19.8\\%), mostly true (18.8\\%), true (14.8\\%)\n",
            "100% 10/10 [00:12<00:00,  1.25s/it]\n",
            "/usr/local/lib/python3.7/dist-packages/hypopt/model_selection.py:174: UserWarning: ERROR in thread<_MainProcess(MainProcess, started)>with exception:\n",
            "module 'sklearn.metrics' has no attribute 'scorer'\n",
            "  warnings.warn('ERROR in thread' + pname + \"with exception:\\n\" + str(e))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96Nym0epwmZh"
      },
      "source": [
        "!python main.py --dataset snes --inputtype CLAIM_ONLY --model bow"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7H6AEqj4Xlzu",
        "outputId": "64812d91-d4d1-40de-a771-b8456112ec54"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "colab_requirements.txt\tmodel_selection.py   __pycache__  src\n",
            "fake-news-reasoning\tmulti_fc_publicdata  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITlJnkUw1PFo"
      },
      "source": [
        "#@title Colab Shell\n",
        "%%html\n",
        "<div id=term_demo></div>\n",
        "<script src=\"https://code.jquery.com/jquery-latest.js\"></script>\n",
        "<script src=\"https://cdn.jsdelivr.net/npm/jquery.terminal/js/jquery.terminal.min.js\"></script>\n",
        "<link href=\"https://cdn.jsdelivr.net/npm/jquery.terminal/css/jquery.terminal.min.css\" rel=\"stylesheet\"/>\n",
        "<script>\n",
        "  $('#term_demo').terminal(async function(command) {\n",
        "      if (command !== '') {\n",
        "          try {\n",
        "              let res = await google.colab.kernel.invokeFunction('shell', [command])\n",
        "              let out = res.data['application/json'][0]\n",
        "              this.echo(new String(out))\n",
        "          } catch(e) {\n",
        "              this.error(new String(e));\n",
        "          }\n",
        "      } else {\n",
        "          this.echo('');\n",
        "      }\n",
        "  }, {\n",
        "      greetings: 'Welcome to Colab Shell',\n",
        "      name: 'colab_demo',\n",
        "      height: 250,\n",
        "      prompt: 'colab > '\n",
        "  });"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aArnbkf1xB5w"
      },
      "source": [
        "from fake_news_reasoning import foo"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZriNIeqkxb7l"
      },
      "source": [
        "!mv fake_news_reasoning/code-acl fake_news_reasoning/code_acl"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkLzkbvmxrM_",
        "outputId": "54be0f29-24b9-46b3-a671-bc986f8f671e"
      },
      "source": [
        "!from fake_news_reasoning.code_acl.bias import model_selection"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "from: can't read /var/mail/fake_news_reasoning.code_acl.bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdVQdimLx0rW"
      },
      "source": [
        ""
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ibt62sP6yDFj"
      },
      "source": [
        ""
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KN4ApQJHyEj1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}